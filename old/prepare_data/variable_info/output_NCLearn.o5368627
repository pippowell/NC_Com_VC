running in shell:  /bin/sh
*** loading spack modules ***
:/home/p/ppowell/miniconda3/envs/EEG_Vis_CL/lib/
*** set workdir ***
Training EEGChannelNet with the following parameters: dataset raw, train method 200L.

Namespace(eeg_dataset='/share/klab/datasets/EEG_Visual/eeg_signals_raw_with_mean_std.pth', splits_path='/share/klab/datasets/EEG_Visual/block_splits_by_image_all.pth', split_num=0, subject=0, time_low=20, time_high=460, model_type='EEGChannelNet', model_params='', pretrained_net='', batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, data_workers=4, epochs=1, saveCheck=100, no_cuda=False)
Copied to CUDA
input is
tensor([[[[-5.9000e+01, -1.5000e+01,  2.2000e+01,  ..., -1.5500e+02,
           -1.4100e+02, -1.1100e+02],
          [-4.6000e+01, -2.1000e+01,  3.0000e+00,  ..., -1.1100e+02,
           -9.9000e+01, -7.7000e+01],
          [ 4.1000e+01,  3.5000e+01,  2.6000e+01,  ...,  4.0000e+01,
            3.2000e+01,  2.0000e+01],
          ...,
          [ 6.4000e+02,  6.1000e+02,  1.4000e+02,  ...,  8.2300e+02,
            7.2200e+02,  7.1000e+02],
          [ 6.1700e+02,  5.5800e+02,  7.5000e+01,  ...,  7.1100e+02,
            5.9500e+02,  5.9000e+02],
          [ 4.6400e+02,  4.2200e+02, -1.5300e+02,  ...,  6.6900e+02,
            5.2700e+02,  5.0600e+02]]],


        [[[ 6.0000e+00,  1.0000e+01,  1.2000e+01,  ..., -1.5000e+01,
           -1.1000e+01, -7.0000e+00],
          [ 1.1000e+01,  9.0000e+00,  7.0000e+00,  ..., -2.5000e+01,
           -2.3000e+01, -2.0000e+01],
          [ 5.0000e+00, -8.0000e+00, -2.2000e+01,  ...,  8.4000e+01,
            7.2000e+01,  5.7000e+01],
          ...,
          [ 1.5600e+02, -1.1200e+02, -5.4500e+02,  ...,  2.9000e+02,
            2.5600e+02,  2.6900e+02],
          [ 2.5779e+04,  3.1188e+04,  3.2767e+04,  ..., -5.2350e+03,
            4.8590e+03,  1.0438e+04],
          [ 8.0000e+01,  1.2080e+03,  4.7690e+03,  ...,  1.4200e+02,
            8.0000e+01,  8.9000e+01]]],


        [[[-1.5700e+02, -1.4200e+02, -1.1200e+02,  ..., -7.5000e+01,
           -1.2400e+02, -1.5900e+02],
          [-1.1800e+02, -1.0700e+02, -8.6000e+01,  ..., -4.4000e+01,
           -7.5000e+01, -9.7000e+01],
          [ 2.7000e+01,  2.0000e+01,  1.0000e+01,  ..., -3.0000e+00,
            2.0000e+00,  4.0000e+00],
          ...,
          [ 4.5900e+02,  3.8200e+02,  3.3400e+02,  ...,  1.4290e+03,
            1.0480e+03,  6.2800e+02],
          [ 3.5100e+02,  2.7400e+02,  2.4500e+02,  ...,  1.4210e+03,
            9.8700e+02,  5.2100e+02],
          [ 3.0800e+02,  2.6100e+02,  2.5300e+02,  ...,  1.5340e+03,
            1.0300e+03,  5.1000e+02]]],


        ...,


        [[[ 6.8000e+01,  6.6000e+01,  5.4000e+01,  ...,  4.6000e+01,
            6.5000e+01,  8.3000e+01],
          [ 7.6000e+01,  7.6000e+01,  6.3000e+01,  ...,  4.9000e+01,
            7.1000e+01,  9.5000e+01],
          [-1.0100e+02, -1.1000e+02, -1.0100e+02,  ...,  0.0000e+00,
           -2.7000e+01, -6.2000e+01],
          ...,
          [-2.3600e+02, -9.2000e+01,  1.0000e+01,  ..., -1.7880e+03,
           -1.3510e+03, -8.9300e+02],
          [-2.2700e+02, -6.0000e+01,  6.1000e+01,  ..., -1.8400e+03,
           -1.4300e+03, -9.3500e+02],
          [ 3.9600e+02,  5.8100e+02,  7.0200e+02,  ..., -1.4050e+03,
           -9.2500e+02, -3.8000e+02]]],


        [[[-2.2000e+01,  9.0000e+00,  4.5000e+01,  ..., -1.1200e+02,
           -8.6000e+01, -6.0000e+01],
          [-2.8000e+01, -6.0000e+00,  1.8000e+01,  ..., -9.4000e+01,
           -7.1000e+01, -4.7000e+01],
          [ 1.8000e+01,  1.1000e+01,  3.0000e+00,  ...,  3.7000e+01,
            2.4000e+01,  1.1000e+01],
          ...,
          [ 5.2300e+02, -1.2900e+02, -2.8000e+02,  ...,  6.8800e+02,
            6.6300e+02,  6.0500e+02],
          [ 4.2800e+02, -2.7100e+02, -4.3200e+02,  ...,  5.7100e+02,
            5.3600e+02,  4.6700e+02],
          [ 2.4900e+02, -5.4600e+02, -7.4600e+02,  ...,  3.6800e+02,
            3.2400e+02,  2.5400e+02]]],


        [[[-6.7000e+01, -5.5000e+01, -4.2000e+01,  ..., -5.6000e+01,
           -4.1000e+01, -2.4000e+01],
          [-7.3000e+01, -5.8000e+01, -4.2000e+01,  ..., -8.0000e+01,
           -6.6000e+01, -4.8000e+01],
          [ 2.9000e+01,  6.0000e+00, -1.7000e+01,  ...,  1.1100e+02,
            9.2000e+01,  6.7000e+01],
          ...,
          [-1.6000e+02, -1.1500e+03, -1.3550e+03,  ...,  9.9000e+01,
            7.0000e+01,  1.0000e+00],
          [-2.3800e+02, -1.2890e+03, -1.4920e+03,  ..., -4.0000e+00,
            1.8000e+01, -3.6000e+01],
          [-1.1200e+02, -1.2570e+03, -1.4980e+03,  ...,  2.0600e+02,
            2.1600e+02,  1.2500e+02]]]])
input is of size
torch.Size([16, 1, 128, 440])
target is
tensor([27,  4, 27,  6,  3,  4,  7,  9, 12, 17, 20, 24,  6, 39, 20,  8])
target of size
torch.Size([16])
output is
tensor([[-7.5466e-02,  2.7423e-01, -1.6417e-01,  8.3654e-02, -1.9970e-01,
          2.2755e-01,  9.3664e-02,  3.0253e-01,  1.6206e-01,  1.7795e-01,
          2.9391e-02,  5.4905e-02,  1.4401e-01,  7.2668e-02, -8.0200e-02,
          1.6875e-02, -1.1602e-01,  9.9788e-02, -1.0481e-02, -1.6275e-01,
         -6.7381e-02, -1.0915e-01,  1.6398e-02,  1.7065e-01, -2.5302e-01,
         -1.6440e-01, -2.2578e-01, -3.5207e-02, -1.2492e-01,  1.8207e-01,
          7.1603e-02,  2.5976e-02,  6.6933e-02, -1.7236e-01, -1.1633e-01,
          7.6099e-02,  3.5132e-02,  2.3681e-02, -4.7161e-03, -2.5748e-02],
        [-1.5117e-01,  7.5911e-02,  1.1050e-01,  3.2000e-01,  5.4261e-04,
          2.1525e-01,  3.9684e-01, -9.4923e-02,  4.3133e-02,  2.1212e-01,
         -3.5116e-02,  2.5612e-01,  3.2595e-01, -3.3368e-01, -1.0024e-01,
          4.0791e-01, -2.5531e-01,  1.4391e-01, -4.0507e-01, -1.1233e-02,
         -5.6930e-02,  2.9569e-02,  1.5810e-01,  2.4377e-01, -2.0829e-01,
         -1.4117e-01, -1.0314e-01,  3.9660e-02,  2.0779e-02,  5.2205e-02,
         -9.2521e-02,  3.0574e-02, -1.4924e-01, -2.0365e-01, -1.0296e-01,
          1.8891e-01,  1.0370e-02, -1.9567e-02, -2.3117e-01,  3.1630e-02],
        [ 3.4709e-03, -3.7289e-03,  1.2074e-01,  1.5509e-02, -1.2651e-01,
          1.4472e-01,  1.6289e-01,  6.5719e-02,  1.4953e-01,  7.2379e-02,
          4.5005e-02, -7.7168e-03,  1.8797e-01, -9.9073e-02, -2.2016e-01,
          1.6346e-01, -1.9614e-01,  8.5740e-02, -2.8457e-01, -5.1467e-02,
         -8.4802e-02, -1.0690e-01, -4.2116e-03,  1.3846e-01,  2.3876e-02,
         -8.6216e-02,  7.6746e-02,  1.0709e-01,  9.5641e-02, -2.9509e-02,
         -7.4660e-02, -5.8116e-03, -8.0292e-02,  1.0814e-01, -5.8301e-02,
          2.0804e-01, -1.6169e-03,  1.8380e-02, -1.8032e-01,  5.0552e-02],
        [-2.2120e-03,  1.6416e-02, -7.8280e-02,  4.2301e-03,  2.8342e-02,
          7.5833e-02,  1.7490e-02, -4.2583e-03,  5.4487e-02,  2.6619e-02,
          1.3770e-03, -2.1498e-03, -1.8554e-02, -1.1234e-01,  5.2835e-02,
          1.0450e-01, -1.3113e-01,  3.9942e-02, -9.0941e-02, -6.4335e-02,
         -9.1277e-02,  1.0923e-02, -3.0207e-03, -8.0817e-02, -5.1727e-02,
         -5.8411e-02,  8.0677e-03, -5.6931e-02, -2.0651e-02,  1.1971e-02,
         -2.3222e-02, -1.6869e-02, -5.0052e-02,  1.8939e-02, -4.8637e-02,
          2.0531e-02, -3.3573e-02, -3.7923e-02, -3.3905e-02,  6.8232e-02],
        [ 3.6469e-02,  8.9310e-02, -5.6920e-02, -1.4484e-01,  3.5334e-02,
          1.0946e-01,  5.4088e-02, -1.4051e-01,  7.3690e-02,  7.4575e-02,
         -2.1466e-02, -8.4549e-02,  1.8727e-01, -1.6234e-01, -1.9415e-02,
          3.4438e-01, -1.2616e-01,  1.6297e-01, -1.7483e-01,  4.1145e-02,
         -1.9311e-01,  1.8397e-02,  1.4247e-01,  4.4053e-02, -1.3469e-01,
         -8.7306e-02,  5.7180e-03, -6.0286e-02,  1.0981e-02,  1.2401e-01,
         -4.3576e-02, -5.3895e-02, -5.1978e-02,  3.3908e-02, -8.3682e-03,
         -4.5093e-02, -3.8289e-02,  6.1622e-02,  2.6244e-02, -1.4386e-01],
        [-4.3887e-02,  3.0843e-02, -4.0803e-02, -1.0640e-02, -6.9227e-02,
          5.8260e-02, -1.5447e-03, -4.4561e-02, -7.4259e-02,  4.1880e-02,
         -3.2620e-02,  7.8151e-02,  2.8084e-02, -8.8929e-03, -3.1769e-02,
          1.1181e-01,  7.9493e-04, -3.1047e-02, -2.7059e-02, -3.2901e-02,
         -2.8178e-02, -4.8060e-03, -1.3075e-02,  1.8456e-02, -7.7809e-03,
         -7.9463e-02,  4.7726e-02, -1.0831e-01,  1.7315e-04,  4.0681e-02,
          8.4458e-02, -7.8183e-02, -6.4851e-02,  6.1104e-02,  6.4815e-02,
         -6.7134e-02, -2.1137e-02,  5.4800e-02, -1.0876e-01, -3.4862e-02],
        [ 2.5641e-02, -1.4026e-02, -4.9487e-02,  2.7980e-02, -1.6040e-02,
          2.3878e-02,  4.8591e-02, -8.7506e-03,  5.2203e-02,  8.5022e-04,
         -8.0136e-03,  5.7848e-02, -2.4065e-02, -4.4738e-02, -5.1052e-02,
          7.0748e-02, -7.8950e-02,  6.9714e-02, -4.5246e-02, -4.3525e-02,
         -5.8447e-02,  4.0367e-02, -2.6457e-02,  2.4956e-02, -7.5641e-02,
         -2.1810e-02,  2.8956e-02,  1.3381e-02,  1.2136e-02,  8.5462e-02,
         -8.3191e-03,  1.2303e-04, -4.5912e-02,  2.4730e-02,  9.0449e-03,
          6.4909e-02,  3.0028e-02,  4.2891e-02, -3.5872e-02, -3.0176e-02],
        [ 8.2140e-02, -3.3447e-02,  7.7335e-02,  2.0286e-01,  2.2072e-01,
          6.9441e-02,  3.3525e-01, -3.7237e-01,  3.2673e-01,  2.1340e-01,
         -1.1953e-01,  1.3685e-01, -9.6723e-02, -5.7112e-01,  9.0735e-02,
          2.5067e-01, -2.9065e-01,  1.7781e-01, -6.0154e-02, -6.7275e-02,
         -4.3618e-02, -1.8639e-02,  2.9588e-01,  2.3617e-01, -1.9054e-01,
         -3.3389e-01, -4.9831e-01,  1.6078e-01,  1.6231e-01, -1.9065e-01,
         -2.0541e-01,  3.9406e-01, -3.3631e-01,  3.6058e-01, -1.2058e-01,
          2.0480e-01, -2.8703e-02, -2.1920e-01,  2.6837e-01, -1.8101e-01],
        [ 9.7679e-02,  5.0821e-03, -7.9879e-02,  6.3677e-02, -7.5109e-02,
          1.4922e-01,  1.4561e-01, -2.0284e-02, -2.0083e-02,  1.2125e-01,
         -1.1223e-01,  1.2828e-02,  1.4120e-01, -5.6369e-02,  7.2784e-02,
          6.7210e-03, -8.1399e-02,  1.1012e-01, -2.4535e-01, -1.2455e-01,
         -7.2341e-02, -2.0830e-02, -8.2197e-02,  7.6851e-02, -1.6481e-01,
         -6.8418e-02,  4.9963e-02, -1.6998e-01, -8.1497e-02,  7.9174e-02,
         -6.1108e-02, -5.2929e-02,  1.0274e-01, -4.5506e-02, -8.3116e-02,
          5.9087e-02, -6.6688e-02, -2.7087e-04, -1.2587e-01,  1.1325e-01],
        [-5.6193e-02,  2.2178e-03, -4.8959e-02, -1.3312e-02,  2.8541e-02,
          6.0405e-02,  3.4825e-02,  4.5243e-02,  4.8729e-02, -8.2209e-03,
         -1.4828e-02,  6.9387e-03, -8.9496e-03, -6.2332e-02, -7.2024e-02,
          1.6343e-01, -6.0171e-02,  3.0358e-02, -4.5908e-02, -3.4532e-02,
         -1.5191e-01,  4.8574e-02, -1.7442e-02,  6.4257e-02, -1.3944e-01,
         -2.2420e-02, -9.5572e-03, -1.3039e-03,  2.3473e-03,  2.5822e-02,
         -1.5592e-02, -5.1103e-02, -7.3853e-02,  1.3315e-02, -6.6423e-02,
          1.2352e-01, -5.7089e-02,  8.6901e-03, -2.9855e-02, -3.2030e-02],
        [ 6.2201e-02, -5.9689e-02,  3.6779e-02,  1.1415e-01,  5.9456e-02,
          1.9450e-01,  2.1481e-01, -1.4000e-01,  8.6343e-02,  1.8023e-01,
          1.7981e-02,  1.0904e-01,  1.3108e-01, -1.5233e-01, -1.2966e-01,
          4.3081e-01, -7.5071e-02,  6.9118e-03, -2.3374e-01, -1.7257e-01,
         -1.5906e-01,  6.2141e-03, -1.0023e-02,  8.4762e-02, -1.5644e-01,
         -3.7567e-02, -4.5234e-02, -1.6564e-02, -4.7572e-02,  5.0361e-02,
          7.1569e-02,  7.5247e-02, -9.0398e-02,  8.7238e-02,  5.9099e-02,
          1.2611e-01, -1.2555e-01, -4.6313e-02, -2.1679e-01, -2.6306e-02],
        [ 4.9012e-03,  1.9176e-02, -7.0838e-02,  4.4012e-02, -3.2000e-02,
          5.7275e-02, -9.3444e-03,  2.2205e-03, -1.4448e-02,  2.8418e-02,
          4.4880e-02,  9.3073e-03,  3.5230e-02, -4.5510e-02, -4.5454e-02,
          1.2284e-01, -5.5373e-02,  6.2136e-02, -1.0526e-01, -9.0560e-02,
         -3.6959e-02,  2.3565e-02, -1.9881e-02,  4.1468e-03, -6.4850e-02,
         -5.6364e-02, -8.6670e-04, -6.8214e-02, -4.6706e-03, -6.9860e-03,
          1.9522e-02, -2.5398e-02, -1.5509e-02,  4.8471e-03,  3.1470e-02,
          5.4787e-03, -4.8237e-03,  2.3189e-02, -4.9740e-02, -2.2319e-02],
        [ 5.1283e-02, -1.0373e-02, -1.8401e-02,  1.8719e-02, -3.4604e-02,
          9.4524e-02,  4.4708e-03,  1.8496e-02,  1.9418e-02,  5.2551e-02,
         -1.4610e-02,  4.0887e-02,  3.2604e-02, -1.8034e-02, -6.0171e-02,
          1.1147e-01, -9.1298e-02,  7.7681e-02, -6.2561e-02, -7.3733e-02,
          3.6109e-02,  4.1450e-02, -3.0177e-02,  3.1580e-02, -1.5161e-03,
         -5.0543e-02,  1.2441e-02, -6.1775e-02, -2.2524e-02, -2.4465e-02,
         -1.6505e-02, -6.1722e-02,  4.4739e-03,  1.9485e-02,  3.2512e-02,
          4.2429e-02,  4.9142e-02,  4.4961e-02, -1.6094e-02, -3.5058e-04],
        [-9.0483e-02, -7.0850e-02, -7.7392e-02,  2.9395e-02, -5.9026e-03,
         -2.9478e-02,  7.1062e-02, -3.0377e-02,  1.6002e-02,  5.7414e-02,
         -5.3425e-03,  5.8185e-02,  3.3598e-02, -4.3051e-02, -1.0495e-01,
          6.7710e-02, -6.6352e-02,  6.9831e-02, -9.8535e-02, -1.3300e-01,
         -2.0573e-02, -3.5818e-02, -2.0090e-02,  5.4735e-02, -5.7441e-02,
         -8.8793e-02, -4.8623e-02, -6.5699e-02, -6.5244e-02,  1.1530e-02,
          4.2109e-03, -2.1019e-02, -4.9312e-02,  6.0395e-02,  1.6824e-02,
          4.7500e-02, -4.2606e-02, -5.3634e-02, -1.8800e-02, -4.5776e-02],
        [ 3.8200e-02, -1.8476e-01,  7.6513e-02,  1.0152e-01, -6.0591e-02,
          1.2452e-01,  6.7902e-02,  1.8583e-01, -1.7714e-01,  7.9711e-02,
         -3.4882e-02, -4.9260e-02,  9.4030e-02, -1.3953e-01,  1.1687e-01,
          2.0438e-01,  8.4606e-02,  6.6301e-03, -1.2505e-01, -7.2014e-02,
         -1.0047e-02, -1.4612e-02, -1.7833e-01,  8.7405e-02, -1.6843e-02,
         -1.4827e-02, -9.3581e-02, -1.1630e-01, -7.0822e-02, -3.5817e-03,
         -2.0392e-01, -1.9936e-02,  1.1278e-02, -4.9267e-02,  1.1244e-01,
          2.7258e-01,  1.3925e-01,  3.3322e-03, -2.7150e-03, -1.1564e-01],
        [ 3.6180e-02, -2.0567e-03, -6.1989e-02,  5.3505e-02, -3.9882e-03,
          7.4899e-02,  9.8289e-03,  1.0973e-02,  7.5445e-02,  4.6586e-02,
          2.1875e-02,  5.4212e-02,  8.3147e-03, -3.9200e-02, -6.3544e-02,
          8.8112e-02, -5.8467e-02,  4.2199e-02, -7.4541e-02, -9.0545e-02,
         -4.8122e-02,  3.8361e-02,  1.3975e-02, -1.7336e-02, -8.5875e-02,
         -1.0190e-01, -1.2633e-02, -4.2787e-02, -6.1959e-03, -5.2838e-02,
          6.3910e-02, -1.0900e-01, -9.4313e-02, -1.2936e-02, -1.3950e-02,
          5.3584e-02, -8.0871e-03, -1.9045e-03, -5.1329e-02, -7.5555e-03]],
       device='cuda:0', grad_fn=<AddmmBackward0>)
output of size
torch.Size([16, 40])
